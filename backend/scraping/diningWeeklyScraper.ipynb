{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Ava's Cafe\": '7',\n",
       " 'Bay Leaf': '14',\n",
       " 'Bites': '22',\n",
       " \"Calabaloo's\": '16',\n",
       " 'Cascadia Cafe': '3',\n",
       " 'Cascadia Deli': '4',\n",
       " 'Cascadia Market': '5',\n",
       " 'Clubhouse Deli': '9',\n",
       " 'Coffee Corral': '8',\n",
       " \"Cooper's Creek\": '10',\n",
       " 'Dixon Cafe': '2',\n",
       " 'e.Cafe': '6',\n",
       " 'East Side Eats': '17',\n",
       " 'EBGBs': '11',\n",
       " 'Five Four One': '18',\n",
       " 'Global Fare': '27',\n",
       " 'Grill': '30',\n",
       " 'Java II': '32',\n",
       " 'JavaStop': '23',\n",
       " 'La Calle': '19',\n",
       " 'Nori': '28',\n",
       " 'North Porch Cafe': '24',\n",
       " 'Off The Quad': '25',\n",
       " 'Raintree Coffee Co.': '20',\n",
       " 'Ring of Fire': '12',\n",
       " 'Serrano Grill': '13',\n",
       " 'Southside Station Deli': '26',\n",
       " 'Southside Station Pizzeria': '29',\n",
       " 'The Dam': '31',\n",
       " \"Trader Bing's Cafe\": '1',\n",
       " 'West Side Grill': '15',\n",
       " 'The MainSqueeze': '21',\n",
       " \"Bing's at Weatherford\": '33'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getRestIDMap():\n",
    "    menus = {}\n",
    "    url = \"https://my.uhds.oregonstate.edu/api/dining/weeklymenu/1\"\n",
    "    response = requests.get(url)\n",
    "    soup = bs.BeautifulSoup(response.text, 'html.parser')\n",
    "    locations = soup.find('select', id='locations')\n",
    "    options = locations.find_all('option')\n",
    "    for option in options:\n",
    "        location = option.text.strip()\n",
    "        location = location.replace('é', 'e')\n",
    "        value = option['value']\n",
    "        menus[location] = value\n",
    "\n",
    "    # rename the key to a different name\n",
    "    menus['The MainSqueeze'] = menus.pop('The Main Squeeze')\n",
    "    menus[\"Bing's at Weatherford\"] = menus.pop(\"Bing's Cafe\")\n",
    "    return menus\n",
    "rest_id_map = getRestIDMap()\n",
    "display(rest_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soup = bs.BeautifulSoup(requests.get('https://my.uhds.oregonstate.edu/api/drupal/hours').text, 'html.parser')\n",
    "\n",
    "page = soup.find('div', class_='pure-g')\n",
    "buildings = page.find_all('h1', class_='zone')\n",
    "groups = page.find_all('div', class_='pure-g')\n",
    "\n",
    "rest_list = []\n",
    "\n",
    "for building, group in zip(buildings, groups):\n",
    "    for restaurant in group.findChildren('div', recursive=False):\n",
    "        if '*' in restaurant.a.text:\n",
    "            continue\n",
    "        rest = {}\n",
    "\n",
    "        rest['detail_url'] = restaurant.a.get('href')\n",
    "        rest['dining_hall'] = building.text.strip()\n",
    "\n",
    "        detail_url = restaurant.a.get('href')\n",
    "        rest_soup = bs.BeautifulSoup(requests.get(detail_url).content, 'html.parser')\n",
    "        content = rest_soup.find('div', id='content')\n",
    "        img = content.find('img')\n",
    "        img_url = \"\"\n",
    "        if img:\n",
    "            img_url = \"https://uhds.oregonstate.edu\" + img.get('src')\n",
    "        rest['img_url'] = img_url\n",
    "        info = content.find('iframe').parent.parent\n",
    "\n",
    "        name = info.findChildren()[0].text.strip() or info.findChildren()[1].text.strip()\n",
    "        name = name.replace('é', 'e')\n",
    "        name = name.replace('\\xa0', ' ')\n",
    "\n",
    "        rest_id = rest_id_map[name]\n",
    "\n",
    "        rest['name'] = name\n",
    "        \n",
    "        desc = info.find('p').text.strip()\n",
    "\n",
    "        rest['description'] = desc\n",
    "\n",
    "        rest_id = rest_id_map[name]\n",
    "        rest['id'] = rest_id\n",
    "\n",
    "        menu_url = f'https://my.uhds.oregonstate.edu/api/dining/weeklymenu/{rest_id}/true'\n",
    "        rest['menu_url'] = menu_url\n",
    "\n",
    "        # find p tag with text 'Location'\n",
    "        location_tag = rest_soup.find('p', string=re.compile('Location'))\n",
    "        address = location_tag.find_next_sibling('p').text.strip().replace('\\n', ', ').replace('\\t', '')\n",
    "        if address == \"\":\n",
    "            address = location_tag.find_next_sibling('p').find_next_sibling('p').text.strip().replace('\\n', ', ').replace('\\t', '')\n",
    "        rest['address'] = address\n",
    "\n",
    "        time_divs = restaurant.find_all('div', class_='time')\n",
    "\n",
    "        # print today's date in number format November 27th\n",
    "        today = datetime.datetime.now()\n",
    "\n",
    "        times = {}\n",
    "        times[today.strftime(\"%B %d\")] = []\n",
    "        for time_div in time_divs: times[today.strftime(\"%B %d\")].append(time_div.text.strip())\n",
    "\n",
    "        more_hours = restaurant.find('div', class_='more_hours')\n",
    "        delta_day = datetime.timedelta(days=1)\n",
    "\n",
    "        for element in more_hours.children:\n",
    "            if element.name == 'strong':\n",
    "                today += delta_day\n",
    "                times[today.strftime(\"%B %d\")] = []\n",
    "            elif element.name == 'em':\n",
    "                times[today.strftime(\"%B %d\")].append(element.text)\n",
    "\n",
    "        rest['times'] = times\n",
    "        \n",
    "        weekly_menu = defaultdict(list)\n",
    "        menus = bs.BeautifulSoup(requests.get(rest['menu_url']).content, 'html.parser')\n",
    "        sections = menus.find_all('div', class_='section')\n",
    "\n",
    "        if sections == []:\n",
    "            rest['menu'] = {}\n",
    "            continue\n",
    "        \n",
    "        for section in sections:\n",
    "            title = section.find('h6').text.strip()\n",
    "            date = title.split('-')[-1].replace(\"th\", \"\").replace(\"nd\", \"\").replace(\"rd\", \"\").replace(\"st\", \"\").strip()\n",
    "            ingredients = [p.text.strip() for p in section.find_all('p')]\n",
    "            weekly_menu[date].append({'title': title, 'ingredients': ingredients})\n",
    "\n",
    "        rest['menu'] = weekly_menu\n",
    "        rest_list.append(rest)\n",
    "\n",
    "\n",
    "# json.dump(rest_list, open('rest.json', 'w'), indent=4)\n",
    "display(len(rest_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
